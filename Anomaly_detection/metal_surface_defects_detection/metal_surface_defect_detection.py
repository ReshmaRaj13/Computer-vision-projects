# -*- coding: utf-8 -*-
"""Metal_surface_defect_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RJVrfG950D3SlCquq_QDZTAROtQMu4is
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("fantacher/neu-metal-surface-defects-data")

print("Path to dataset files:", path)

import numpy as np
import cv2
import os
import glob
import joblib
from skimage.feature import graycomatrix, graycoprops, local_binary_pattern, hog
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder, StandardScaler

image_path = os.path.join(path, "NEU Metal Surface Defects Data","train")
categories = os.listdir(image_path)
print(categories)

# Load dataset
def load_images(folder, label):
    images = []
    labels = []
    for file in glob.glob(folder + "/*.bmp"):  # Adjust for your dataset
        img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)
        img = cv2.resize(img, (128, 128))  # Resize for consistency
        images.append(img)
        labels.append(label)
    return images, labels

train_images, train_labels = [], []
train_image_path = os.path.join(path, "NEU Metal Surface Defects Data","train")
for category in categories:
    folder_path = os.path.join(train_image_path, category)
    images, labels = load_images(folder_path, label=category)
    train_images.extend(images)
    train_labels.extend(labels)
train_images = np.array(train_images)
train_labels = np.array(train_labels)

print(train_labels.shape)

test_images, test_labels = [], []
test_image_path = os.path.join(path, "NEU Metal Surface Defects Data","test")
for category in categories:
    folder_path = os.path.join(test_image_path, category)
    images, labels = load_images(folder_path, label=category)
    test_images.extend(images)
    test_labels.extend(labels)
test_images = np.array(test_images)
test_labels = np.array(test_labels)

val_images, val_labels = [], []
val_image_path = os.path.join(path, "NEU Metal Surface Defects Data","test")
for category in categories:
    folder_path = os.path.join(val_image_path, category)
    images, labels = load_images(folder_path, label=category)
    val_images.extend(images)
    val_labels.extend(labels)
val_images = np.array(val_images)
val_labels = np.array(val_labels)

import matplotlib.pyplot as plt
import numpy as np
import os

# Assuming you have already loaded train_images and train_labels

# Create a dictionary to store images for each category
category_images = {}
for i, label in enumerate(train_labels):
    if label not in category_images:
        category_images[label] = []
    category_images[label].append(train_images[i])

# Display one image from each category
plt.figure(figsize=(5, 5))
for i, (category, images) in enumerate(category_images.items()):
    plt.subplot(3, 3, i + 1)  # Adjust grid layout as needed
    plt.imshow(images[0].astype("uint8"), cmap='gray')  # Display the first image of the category
    plt.title(category)
    plt.axis("off")

plt.show()

# Feature extraction
def extract_features(images):
    feature_list = []
    for img in images:
        # GLCM (Texture features)
        glcm = graycomatrix(img, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)
        contrast = graycoprops(glcm, 'contrast')[0, 0]
        dissimilarity = graycoprops(glcm, 'dissimilarity')[0, 0]
        homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]
        energy = graycoprops(glcm, 'energy')[0, 0]

        # LBP (Texture descriptor)
        lbp = local_binary_pattern(img, P=8, R=1, method="uniform")
        lbp_hist, _ = np.histogram(lbp, bins=np.arange(0, 11), density=True)

        # HOG (Shape features)
        hog_features = hog(img, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True)

        # Combine features
        features = [contrast, dissimilarity, homogeneity, energy] + list(lbp_hist) + list(hog_features)
        feature_list.append(features)

    return np.array(feature_list)

# Encode labels
le = LabelEncoder()
y_train = le.fit_transform(train_labels)
y_test = le.transform(test_labels)
y_val = le.transform(val_labels)

# Extract features
X_train= extract_features(train_images)
X_test = extract_features(test_images)
X_val = extract_features(val_images)

# Standardize features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
X_val = scaler.transform(X_val)



# Train models
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

svm_model = SVC(kernel='linear', C=1.0)
svm_model.fit(X_train, y_train)

# Evaluate models
rf_pred = rf_model.predict(X_test)
svm_pred = svm_model.predict(X_test)

print("Random Forest Accuracy:", accuracy_score(y_test, rf_pred))
print("SVM Accuracy:", accuracy_score(y_test, svm_pred))
print("\nRandom Forest Classification Report:\n", classification_report(y_test, rf_pred))
print("\nSVM Classification Report:\n", classification_report(y_test, svm_pred))

import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

# Apply PCA to reduce dimensionality to 2D
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_train)

# Scatter plot of first two principal components
plt.figure(figsize=(6,6))
scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_train, cmap="viridis", alpha=0.7)
plt.legend(handles=scatter.legend_elements()[0], labels=categories)
plt.title("PCA Visualization of Extracted Features")
plt.xlabel("Principal Component 1")
plt.ylabel("Principal Component 2")
plt.show()

svm_model_rbf = SVC(kernel='rbf', C=1.0, gamma='scale')
svm_model_rbf.fit(X_train, y_train)
svm_pred_rbf = svm_model_rbf.predict(X_test)
print("SVM (RBF) Accuracy:", accuracy_score(y_test, svm_pred_rbf))

val_pred = rf_model.predict(X_val) # Use your trained model (rf_model or svm_model)
val_pred_labels = le.inverse_transform(val_pred) # Convert predictions back to original labels
val_true_labels = le.inverse_transform(y_val) # Convert true labels back to original labels

import matplotlib.pyplot as plt

# Create a figure and axes
fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(8, 8))  # Adjust grid as needed

# Plot a few validation images with predictions and true labels
for i, ax in enumerate(axes.flat):
    ax.imshow(val_images[i].astype("uint8"), cmap='gray')
    ax.set_title(f"Pred: {val_pred_labels[i]}, True: {val_true_labels[i]}")
    ax.axis("off")

plt.tight_layout()
plt.show()

# Save models
joblib.dump(rf_model, "metal_defect_rf_model.pkl")
joblib.dump(svm_model, "metal_defect_svm_model.pkl")
joblib.dump(scaler, "scaler.pkl")
joblib.dump(le, "label_encoder.pkl")

